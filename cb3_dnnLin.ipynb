{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24462128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Achu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\__init__.py:16: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.5)\n",
      "  from scipy.sparse import issparse\n"
     ]
    }
   ],
   "source": [
    "import os, math, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0821e54-b375-4e98-950e-f716ade84a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65216e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = pickle.load(open(r'C:\\CB\\q3\\train.pkl', 'rb')).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e674d7f-6941-4f34-87dc-2f28b51e9297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988ad1d7-9d5b-4840-a793-fea031da6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], unit='D', origin='2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8692de3-5546-495c-ab83-9c84724e0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values([\"code\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e95bd87-a2c6-4fbe-a81b-319d489964f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode series id (fast and compact)\n",
    "df[\"code_id\"] = df[\"code\"].astype(\"category\").cat.codes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b610a4e6-47dd-40f5-8c1b-56107c001db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2431658  | Series: 4925  | Base features: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>y</th>\n",
       "      <th>code_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_0</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>-0.063500</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048135</td>\n",
       "      <td>0.582772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.952015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130791</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_0</td>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>0.302114</td>\n",
       "      <td>-0.039620</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.571028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.718900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.322955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.132136</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_0</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>0.210442</td>\n",
       "      <td>-0.021979</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035704</td>\n",
       "      <td>0.566825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.529921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.203602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>0.121744</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_0</td>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>0.091796</td>\n",
       "      <td>-0.014817</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.073599</td>\n",
       "      <td>0.562066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.483651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.197761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.115516</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.030045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_0</td>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.010519</td>\n",
       "      <td>9.651191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.105692</td>\n",
       "      <td>0.548534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.224910</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.040731</td>\n",
       "      <td>0.103038</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.038166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code       date       f_0       f_1       f_2  f_3       f_4       f_5  f_6  \\\n",
       "0  s_0 2024-05-01  0.394700 -0.063500  7.562500  0.0  0.048135  0.582772  0.0   \n",
       "1  s_0 2024-05-02  0.302114 -0.039620  7.562500  0.0  0.003498  0.571028  0.0   \n",
       "2  s_0 2024-05-03  0.210442 -0.021979  7.562500  0.0 -0.035704  0.566825  0.0   \n",
       "3  s_0 2024-05-04  0.091796 -0.014817  7.562500  0.0 -0.073599  0.562066  0.0   \n",
       "4  s_0 2024-05-05 -0.000065 -0.010519  9.651191  0.0 -0.105692  0.548534  0.0   \n",
       "\n",
       "        f_7  f_8       f_9  f_10  f_11      f_12      f_13      f_14  \\\n",
       "0  1.952015  0.0  0.933833   0.0   0.0  1.452481  0.000000  0.000000   \n",
       "1  1.718900  0.0  0.921778   0.0   0.0  1.322955  0.000000  0.000000   \n",
       "2  1.529921  0.0  0.915979   0.0   0.0  1.203602  0.000000  0.000000   \n",
       "3  1.483651  0.0  0.919647   0.0   0.0  1.197761  0.000000  0.000000   \n",
       "4  1.482967  0.0  0.921448   0.0   0.0  1.224910 -0.017885 -0.032768   \n",
       "\n",
       "       f_15      f_16      f_17      f_18  f_19         y  code_id  \n",
       "0  0.000000  0.130791  0.000070 -0.009330   0.0 -0.046793        0  \n",
       "1  0.007457  0.132136  0.000037 -0.000959   0.0 -0.001007        0  \n",
       "2  0.017134  0.121744  0.000026  0.024070   0.0  0.057230        0  \n",
       "3  0.030256  0.115516 -0.000006  0.030045   0.0 -0.018251        0  \n",
       "4  0.040731  0.103038 -0.000039  0.023343   0.0 -0.038166        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify base feature columns\n",
    "base_feats = [c for c in df.columns if c.startswith(\"f_\")]\n",
    "print(\"Rows:\", len(df), \" | Series:\", df[\"code\"].nunique(), \" | Base features:\", len(base_feats))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21d0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"t_idx\"] = df.groupby(\"code\").cumcount().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19058a88-239b-4498-ba86-ad3aadaae8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature cols: 43\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>code_id</th>\n",
       "      <th>t_idx</th>\n",
       "      <th>y_lag_1</th>\n",
       "      <th>y_lag_2</th>\n",
       "      <th>y_lag_3</th>\n",
       "      <th>y_lag_7</th>\n",
       "      <th>y_roll_mean_3</th>\n",
       "      <th>y_roll_std_3</th>\n",
       "      <th>y_roll_mean_7</th>\n",
       "      <th>y_roll_std_7</th>\n",
       "      <th>sin_7</th>\n",
       "      <th>cos_7</th>\n",
       "      <th>sin_30</th>\n",
       "      <th>cos_30</th>\n",
       "      <th>sin_90</th>\n",
       "      <th>cos_90</th>\n",
       "      <th>sin_365</th>\n",
       "      <th>cos_365</th>\n",
       "      <th>dow</th>\n",
       "      <th>dom</th>\n",
       "      <th>month</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>year</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394700</td>\n",
       "      <td>-0.063500</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048135</td>\n",
       "      <td>0.582772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.952015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.933833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.452481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130791</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2024</td>\n",
       "      <td>-0.046793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.302114</td>\n",
       "      <td>-0.039620</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.571028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.718900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.322955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.132136</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.069756</td>\n",
       "      <td>0.997564</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2024</td>\n",
       "      <td>-0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210442</td>\n",
       "      <td>-0.021979</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.035704</td>\n",
       "      <td>0.566825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.529921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.203602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>0.121744</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.024070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.139173</td>\n",
       "      <td>0.990268</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.057230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.091796</td>\n",
       "      <td>-0.014817</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.073599</td>\n",
       "      <td>0.562066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.483651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.197761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030256</td>\n",
       "      <td>0.115516</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.030045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.057230</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2024</td>\n",
       "      <td>-0.018251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.010519</td>\n",
       "      <td>9.651191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.105692</td>\n",
       "      <td>0.548534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.482967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.224910</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.032768</td>\n",
       "      <td>0.040731</td>\n",
       "      <td>0.103038</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.018251</td>\n",
       "      <td>0.057230</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012657</td>\n",
       "      <td>0.039552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>0.275637</td>\n",
       "      <td>0.961262</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2024</td>\n",
       "      <td>-0.038166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2  f_3       f_4       f_5  f_6       f_7  f_8  \\\n",
       "0  0.394700 -0.063500  7.562500  0.0  0.048135  0.582772  0.0  1.952015  0.0   \n",
       "1  0.302114 -0.039620  7.562500  0.0  0.003498  0.571028  0.0  1.718900  0.0   \n",
       "2  0.210442 -0.021979  7.562500  0.0 -0.035704  0.566825  0.0  1.529921  0.0   \n",
       "3  0.091796 -0.014817  7.562500  0.0 -0.073599  0.562066  0.0  1.483651  0.0   \n",
       "4 -0.000065 -0.010519  9.651191  0.0 -0.105692  0.548534  0.0  1.482967  0.0   \n",
       "\n",
       "        f_9  f_10  f_11      f_12      f_13      f_14      f_15      f_16  \\\n",
       "0  0.933833   0.0   0.0  1.452481  0.000000  0.000000  0.000000  0.130791   \n",
       "1  0.921778   0.0   0.0  1.322955  0.000000  0.000000  0.007457  0.132136   \n",
       "2  0.915979   0.0   0.0  1.203602  0.000000  0.000000  0.017134  0.121744   \n",
       "3  0.919647   0.0   0.0  1.197761  0.000000  0.000000  0.030256  0.115516   \n",
       "4  0.921448   0.0   0.0  1.224910 -0.017885 -0.032768  0.040731  0.103038   \n",
       "\n",
       "       f_17      f_18  f_19  code_id  t_idx   y_lag_1   y_lag_2   y_lag_3  \\\n",
       "0  0.000070 -0.009330   0.0        0      0       NaN       NaN       NaN   \n",
       "1  0.000037 -0.000959   0.0        0      1 -0.046793       NaN       NaN   \n",
       "2  0.000026  0.024070   0.0        0      2 -0.001007 -0.046793       NaN   \n",
       "3 -0.000006  0.030045   0.0        0      3  0.057230 -0.001007 -0.046793   \n",
       "4 -0.000039  0.023343   0.0        0      4 -0.018251  0.057230 -0.001007   \n",
       "\n",
       "   y_lag_7  y_roll_mean_3  y_roll_std_3  y_roll_mean_7  y_roll_std_7  \\\n",
       "0      NaN            NaN           NaN            NaN           NaN   \n",
       "1      NaN            NaN           NaN            NaN           NaN   \n",
       "2      NaN            NaN           NaN            NaN           NaN   \n",
       "3      NaN       0.003143      0.052135            NaN           NaN   \n",
       "4      NaN       0.012657      0.039552            NaN           NaN   \n",
       "\n",
       "      sin_7     cos_7    sin_30    cos_30    sin_90    cos_90   sin_365  \\\n",
       "0  0.000000  1.000000  0.000000  1.000000  0.000000  1.000000  0.000000   \n",
       "1  0.781832  0.623490  0.207912  0.978148  0.069756  0.997564  0.017213   \n",
       "2  0.974928 -0.222521  0.406737  0.913545  0.139173  0.990268  0.034422   \n",
       "3  0.433884 -0.900969  0.587785  0.809017  0.207912  0.978148  0.051620   \n",
       "4 -0.433884 -0.900969  0.743145  0.669131  0.275637  0.961262  0.068802   \n",
       "\n",
       "    cos_365  dow  dom  month  weekofyear  year         y  \n",
       "0  1.000000    2    1      5          18  2024 -0.046793  \n",
       "1  0.999852    3    2      5          18  2024 -0.001007  \n",
       "2  0.999407    4    3      5          18  2024  0.057230  \n",
       "3  0.998667    5    4      5          18  2024 -0.018251  \n",
       "4  0.997630    6    5      5          18  2024 -0.038166  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in [1,2,3,7]:\n",
    "    df[f\"y_lag_{l}\"]=df.groupby(\"code\")[\"y\"].shift(l)\n",
    "for w in [3,7]:\n",
    "    df[f\"y_roll_mean_{w}\"]=df.groupby(\"code\")[\"y\"].shift(1).rolling(w).mean()\n",
    "    df[f\"y_roll_std_{w}\"]=df.groupby(\"code\")[\"y\"].shift(1).rolling(w).std()\n",
    "\n",
    "PERIODS = [7, 30, 90, 365]\n",
    "for p in PERIODS:\n",
    "    df[f\"sin_{p}\"] = np.sin(2*np.pi*df[\"t_idx\"]/p).astype(np.float32)\n",
    "    df[f\"cos_{p}\"] = np.cos(2*np.pi*df[\"t_idx\"]/p).astype(np.float32)\n",
    "\n",
    "df[\"dow\"] = df[\"date\"].dt.dayofweek.astype(np.int16)\n",
    "df[\"dom\"] = df[\"date\"].dt.day.astype(np.int16)\n",
    "df[\"month\"] = df[\"date\"].dt.month.astype(np.int16)\n",
    "df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(np.int16)\n",
    "df[\"year\"] = df[\"date\"].dt.year.astype(np.int16)\n",
    "\n",
    "df.dropna()\n",
    "#extra = [\"code_id\",\"t_idx\"] +         [f\"sin_{p}\" for p in PERIODS] + [f\"cos_{p}\" for p in PERIODS]\n",
    "target_col=\"y\"\n",
    "feature_cols=[c for c in df.columns if c not in [\"code\",\"date\",target_col]]\n",
    "\n",
    "#feature_cols = base_feats + extra\n",
    "#target_col = \"y\"\n",
    "\n",
    "print(\"Total feature cols:\", len(feature_cols))\n",
    "df[feature_cols + [target_col]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0fbcb972-50a0-4420-973b-45dd64033e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ba12a682-a7cd-48e0-9ecc-61c0046da8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "549d37e8-73d8-421d-a037-efde390818ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code             0\n",
       "date             0\n",
       "f_0              0\n",
       "f_1              0\n",
       "f_2              0\n",
       "f_3              0\n",
       "f_4              0\n",
       "f_5              0\n",
       "f_6              0\n",
       "f_7              0\n",
       "f_8              0\n",
       "f_9              0\n",
       "f_10             0\n",
       "f_11             0\n",
       "f_12             0\n",
       "f_13             0\n",
       "f_14             0\n",
       "f_15             0\n",
       "f_16             0\n",
       "f_17             0\n",
       "f_18             0\n",
       "f_19             0\n",
       "y                0\n",
       "code_id          0\n",
       "t_idx            0\n",
       "y_lag_1          0\n",
       "y_lag_2          0\n",
       "y_lag_3          0\n",
       "y_lag_7          0\n",
       "y_roll_mean_3    0\n",
       "y_roll_std_3     0\n",
       "y_roll_mean_7    0\n",
       "y_roll_std_7     0\n",
       "sin_7            0\n",
       "cos_7            0\n",
       "sin_30           0\n",
       "cos_30           0\n",
       "sin_90           0\n",
       "cos_90           0\n",
       "sin_365          0\n",
       "cos_365          0\n",
       "dow              0\n",
       "dom              0\n",
       "month            0\n",
       "weekofyear       0\n",
       "year             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fd906-6776-40b5-85d1-c287d9bfc13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40a993-903b-4999-a47f-bfe7c6598a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b340e6-14be-427d-99ba-c669ad886b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "da4b9013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut date: 2025-03-17\n",
      "Train rows: 1877406 Validation rows: 519790\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Date-based split (time-aware)\n",
    "# -----------------------------\n",
    "unique_dates = np.array(sorted(df[\"date\"].unique()))\n",
    "cut = int(math.floor(len(unique_dates) * 0.8))\n",
    "cut_date = unique_dates[cut]\n",
    "\n",
    "train_df = df[df[\"date\"] < cut_date].copy()\n",
    "valid_df  = df[df[\"date\"] >= cut_date].copy()\n",
    "\n",
    "print(\"Cut date:\", pd.to_datetime(cut_date).date())\n",
    "print(\"Train rows:\", len(train_df), \"Validation rows:\", len(valid_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbdb90",
   "metadata": {},
   "source": [
    "## 5) Feature Selection with Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f9884f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_lag_1          0.528938\n",
       "y_roll_mean_3    0.221922\n",
       "y_lag_2          0.181559\n",
       "y_roll_std_7     0.115701\n",
       "t_idx            0.113193\n",
       "y_roll_std_3     0.111945\n",
       "weekofyear       0.078735\n",
       "y_roll_mean_7    0.070293\n",
       "sin_365          0.063143\n",
       "cos_365          0.046158\n",
       "y_lag_3          0.040837\n",
       "dom              0.031382\n",
       "cos_90           0.026320\n",
       "month            0.022556\n",
       "sin_90           0.022504\n",
       "y_lag_7          0.017638\n",
       "cos_30           0.011952\n",
       "f_15             0.010469\n",
       "f_5              0.009342\n",
       "f_0              0.009058\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) Mutual Information Feature Selection (row-level)\n",
    "# -----------------------------\n",
    "X_row = train_df[feature_cols].to_numpy(dtype=np.float32)\n",
    "y_row = train_df[target_col].to_numpy(dtype=np.float32)\n",
    "\n",
    "imp_mi = SimpleImputer(strategy=\"median\")\n",
    "X_row_imp = imp_mi.fit_transform(X_row)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n_sample = min(20000, X_row_imp.shape[0])\n",
    "idx = rng.choice(X_row_imp.shape[0], size=n_sample, replace=False)\n",
    "\n",
    "mi = mutual_info_regression(X_row_imp[idx], y_row[idx], random_state=42)\n",
    "mi_series = pd.Series(mi, index=feature_cols).sort_values(ascending=False)\n",
    "\n",
    "TOP_K = min(35, len(feature_cols))\n",
    "selected_features = mi_series.head(TOP_K).index.tolist()\n",
    "mi_series.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8bb81-d3e4-42f0-8662-ff334ff8991e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ba7f249-5945-49a1-9292-bb01be1ebf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_row.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "784ce260-3c44-4fda-9b46-7f58d8ca567a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1877406,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "80042556-c53d-4215-9ead-3ca52a486596",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = valid_df[target_col].to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8dee26-d7bc-4907-9c88-d82e204f32da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b390b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row feature matrix shapes: (1877406, 28) (519790, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train_row = train_df[selected_features].to_numpy(dtype=np.float32)\n",
    "X_valid_row  = valid_df[selected_features].to_numpy(dtype=np.float32)\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_imp = imp.fit_transform(X_train_row)\n",
    "X_valid_imp  = imp.transform(X_valid_row)\n",
    "\n",
    "X_train_sc = scaler.fit_transform(X_train_imp)\n",
    "X_valid_sc  = scaler.transform(X_valid_imp)\n",
    "\n",
    "PCA_N = min(20, X_train_sc.shape[1])\n",
    "pca = PCA(n_components=PCA_N, random_state=42)\n",
    "Z_train = pca.fit_transform(X_train_sc).astype(np.float32)\n",
    "Z_valid  = pca.transform(X_valid_sc).astype(np.float32)\n",
    "\n",
    "\n",
    "K = 8\n",
    "kmeans = MiniBatchKMeans(n_clusters=K, random_state=42, batch_size=4096, n_init=\"auto\")\n",
    "kmeans.fit(Z_train)\n",
    "\n",
    "D_train = kmeans.transform(Z_train).astype(np.float32)  # distances to centers\n",
    "D_valid  = kmeans.transform(Z_valid).astype(np.float32)\n",
    "\n",
    "F_train = np.hstack([Z_train, D_train]).astype(np.float32)\n",
    "F_valid  = np.hstack([Z_valid,  D_valid]).astype(np.float32)\n",
    "\n",
    "print(\"Row feature matrix shapes:\", F_train.shape, F_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9aa5ddce-22fe-4644-9a4e-cbcb779914d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1877406, 28)\n",
      "(519790, 28)\n"
     ]
    }
   ],
   "source": [
    "print(F_train.shape)\n",
    "print(F_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "025cb70b-88c8-4671-b9a7-b772c32dbd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1877406,)\n",
      "(519790,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "73463369-717f-47bd-a8e2-5f4301f22c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = y_train.reshape(-1, 1)\n",
    "y_vl = y_valid.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "00a56e2e-b8cc-426f-8882-f146887c6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pickle.load(open(r'C:\\CB\\q3\\test.pkl', 'rb')).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d968d2c9-8a52-476f-904c-1157089e5f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2244974</th>\n",
       "      <td>s_4780</td>\n",
       "      <td>550</td>\n",
       "      <td>-0.704179</td>\n",
       "      <td>0.072523</td>\n",
       "      <td>1.990935</td>\n",
       "      <td>0.820878</td>\n",
       "      <td>-0.006093</td>\n",
       "      <td>0.485911</td>\n",
       "      <td>0.040129</td>\n",
       "      <td>0.942753</td>\n",
       "      <td>2.119506</td>\n",
       "      <td>0.934240</td>\n",
       "      <td>0.081470</td>\n",
       "      <td>1.129677</td>\n",
       "      <td>0.949033</td>\n",
       "      <td>-0.058095</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.080117</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.003881</td>\n",
       "      <td>-0.030448</td>\n",
       "      <td>-0.106038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031851</th>\n",
       "      <td>s_2097</td>\n",
       "      <td>550</td>\n",
       "      <td>-1.475341</td>\n",
       "      <td>-0.060034</td>\n",
       "      <td>1.737305</td>\n",
       "      <td>0.675257</td>\n",
       "      <td>0.101021</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.834724</td>\n",
       "      <td>2.751153</td>\n",
       "      <td>0.976950</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>1.146666</td>\n",
       "      <td>0.872422</td>\n",
       "      <td>-0.089398</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>-0.048870</td>\n",
       "      <td>0.016602</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>-0.068891</td>\n",
       "      <td>-0.066604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2433999</th>\n",
       "      <td>s_2157</td>\n",
       "      <td>550</td>\n",
       "      <td>-1.577786</td>\n",
       "      <td>0.074787</td>\n",
       "      <td>1.659307</td>\n",
       "      <td>0.696049</td>\n",
       "      <td>0.076902</td>\n",
       "      <td>0.304876</td>\n",
       "      <td>-0.016647</td>\n",
       "      <td>0.804080</td>\n",
       "      <td>3.097071</td>\n",
       "      <td>0.981946</td>\n",
       "      <td>0.015689</td>\n",
       "      <td>1.223102</td>\n",
       "      <td>0.803156</td>\n",
       "      <td>-0.053105</td>\n",
       "      <td>-0.016663</td>\n",
       "      <td>-0.046717</td>\n",
       "      <td>-0.015627</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.026963</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>-0.011905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402607</th>\n",
       "      <td>s_4105</td>\n",
       "      <td>550</td>\n",
       "      <td>-1.003856</td>\n",
       "      <td>0.033389</td>\n",
       "      <td>1.360022</td>\n",
       "      <td>0.586838</td>\n",
       "      <td>-0.026944</td>\n",
       "      <td>0.450235</td>\n",
       "      <td>0.019490</td>\n",
       "      <td>0.848843</td>\n",
       "      <td>2.781379</td>\n",
       "      <td>0.958969</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>1.153103</td>\n",
       "      <td>0.940588</td>\n",
       "      <td>-0.052266</td>\n",
       "      <td>-0.015170</td>\n",
       "      <td>0.044854</td>\n",
       "      <td>-0.016701</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.038767</td>\n",
       "      <td>-0.031813</td>\n",
       "      <td>0.071741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952904</th>\n",
       "      <td>s_2387</td>\n",
       "      <td>550</td>\n",
       "      <td>-1.260005</td>\n",
       "      <td>-0.068659</td>\n",
       "      <td>2.414646</td>\n",
       "      <td>0.838523</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>0.335265</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.893063</td>\n",
       "      <td>2.625780</td>\n",
       "      <td>0.928790</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>1.016474</td>\n",
       "      <td>0.897439</td>\n",
       "      <td>-0.092461</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0.010151</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0.083079</td>\n",
       "      <td>-0.004084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           code  date       f_0       f_1       f_2       f_3       f_4  \\\n",
       "2244974  s_4780   550 -0.704179  0.072523  1.990935  0.820878 -0.006093   \n",
       "2031851  s_2097   550 -1.475341 -0.060034  1.737305  0.675257  0.101021   \n",
       "2433999  s_2157   550 -1.577786  0.074787  1.659307  0.696049  0.076902   \n",
       "2402607  s_4105   550 -1.003856  0.033389  1.360022  0.586838 -0.026944   \n",
       "1952904  s_2387   550 -1.260005 -0.068659  2.414646  0.838523 -0.094169   \n",
       "\n",
       "              f_5       f_6       f_7       f_8       f_9      f_10      f_11  \\\n",
       "2244974  0.485911  0.040129  0.942753  2.119506  0.934240  0.081470  1.129677   \n",
       "2031851  0.273800  0.003186  0.834724  2.751153  0.976950  0.003297  1.146666   \n",
       "2433999  0.304876 -0.016647  0.804080  3.097071  0.981946  0.015689  1.223102   \n",
       "2402607  0.450235  0.019490  0.848843  2.781379  0.958969 -0.001349  1.153103   \n",
       "1952904  0.335265  0.001841  0.893063  2.625780  0.928790  0.057546  1.016474   \n",
       "\n",
       "             f_12      f_13      f_14      f_15      f_16      f_17      f_18  \\\n",
       "2244974  0.949033 -0.058095  0.016745  0.002501  0.080117 -0.000019 -0.003881   \n",
       "2031851  0.872422 -0.089398  0.022010 -0.048870  0.016602 -0.000008  0.040727   \n",
       "2433999  0.803156 -0.053105 -0.016663 -0.046717 -0.015627 -0.000052  0.026963   \n",
       "2402607  0.940588 -0.052266 -0.015170  0.044854 -0.016701 -0.000013  0.038767   \n",
       "1952904  0.897439 -0.092461  0.021719  0.010151  0.006536 -0.000028 -0.060134   \n",
       "\n",
       "             f_19         y  \n",
       "2244974 -0.030448 -0.106038  \n",
       "2031851 -0.068891 -0.066604  \n",
       "2433999  0.002812 -0.011905  \n",
       "2402607 -0.031813  0.071741  \n",
       "1952904  0.083079 -0.004084  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aeebe87b-ec0a-4e24-ab37-4f0a576c9fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['date'] = pd.to_datetime(df_test['date'], unit='D', origin='2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b79e2f86-d323-4da1-936c-93a92edc3777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sort_values([\"code\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "89294c29-999e-4d15-8815-3266030c651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"code_id\"] = df_test[\"code\"].astype(\"category\").cat.codes.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ce6e908c-c05c-41d2-b31f-99d6094490e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"t_idx\"] = df_test.groupby(\"code\").cumcount().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad90d2-13e2-4e69-9a4d-dbbfeb8d9fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "55ca909b-233e-4f35-a8f6-433bf5b8e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [1,2,3,7]:\n",
    "    df_test[f\"y_lag_{l}\"]=df_test.groupby(\"code\")[\"y\"].shift(l)\n",
    "for w in [3,7]:\n",
    "    df_test[f\"y_roll_mean_{w}\"]=df_test.groupby(\"code\")[\"y\"].shift(1).rolling(w).mean()\n",
    "    df_test[f\"y_roll_std_{w}\"]=df_test.groupby(\"code\")[\"y\"].shift(1).rolling(w).std()\n",
    "\n",
    "PERIODS = [7, 30, 90, 365]\n",
    "for p in PERIODS:\n",
    "    df_test[f\"sin_{p}\"] = np.sin(2*np.pi*df_test[\"t_idx\"]/p).astype(np.float32)\n",
    "    df_test[f\"cos_{p}\"] = np.cos(2*np.pi*df_test[\"t_idx\"]/p).astype(np.float32)\n",
    "\n",
    "df_test[\"dow\"] = df_test[\"date\"].dt.dayofweek.astype(np.int16)\n",
    "df_test[\"dom\"] = df_test[\"date\"].dt.day.astype(np.int16)\n",
    "df_test[\"month\"] = df_test[\"date\"].dt.month.astype(np.int16)\n",
    "df_test[\"weekofyear\"] = df_test[\"date\"].dt.isocalendar().week.astype(np.int16)\n",
    "df_test[\"year\"] = df_test[\"date\"].dt.year.astype(np.int16)\n",
    "\n",
    "X_test = df_test[selected_features].to_numpy(dtype=np.float32)\n",
    "y_test = df_test[target_col].to_numpy(dtype=np.float32)\n",
    "X_test_imp = imp.fit_transform(X_test)\n",
    "X_test_sc = scaler.transform(X_test_imp)\n",
    "\n",
    "Z_test  = pca.transform(X_test_sc).astype(np.float32)\n",
    "D_test =  kmeans.transform(Z_test).astype(np.float32)\n",
    "\n",
    "F_test = np.hstack([Z_test, D_test]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a1f3f78b-edc7-495a-8864-a6db17c147de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833916, 28)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0568a2a1-a665-4510-b5df-a17a0c95b86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833916,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4f28994b-f1fe-46e8-a885-a98f23521370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ACTIVATION FUNCTIONS\n",
      "================================================================================\n",
      "\n",
      "✓ Activation functions defined:\n",
      "  - ReLU for hidden layers: f(z) = max(0, z)\n",
      "  - Identity for output layer: f(z) = z\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ACTIVATION FUNCTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class ActivationFunctions:\n",
    "    \"\"\"\n",
    "    Activation functions and their derivatives for DFNN\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(Z):\n",
    "        \"\"\"\n",
    "        ReLU activation: f(z) = max(0, z)\n",
    "        \n",
    "        Args:\n",
    "            Z: Pre-activation values (any shape)\n",
    "        Returns:\n",
    "            Activated values (same shape as Z)\n",
    "        \"\"\"\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu_derivative(Z):\n",
    "        \"\"\"\n",
    "        ReLU derivative: f'(z) = 1 if z > 0, else 0\n",
    "        \n",
    "        Args:\n",
    "            Z: Pre-activation values (any shape)\n",
    "        Returns:\n",
    "            Derivative values (same shape as Z)\n",
    "        \"\"\"\n",
    "        return (Z > 0).astype(float)\n",
    "    \n",
    "    @staticmethod\n",
    "    def identity(Z):\n",
    "        \"\"\"\n",
    "        Identity activation: f(z) = z\n",
    "        Used for regression output layer\n",
    "        \n",
    "        Args:\n",
    "            Z: Pre-activation values (any shape)\n",
    "        Returns:\n",
    "            Same as input\n",
    "        \"\"\"\n",
    "        return Z\n",
    "    \n",
    "    @staticmethod\n",
    "    def identity_derivative(Z):\n",
    "        \"\"\"\n",
    "        Identity derivative: f'(z) = 1\n",
    "        \n",
    "        Args:\n",
    "            Z: Pre-activation values (any shape)\n",
    "        Returns:\n",
    "            Ones with same shape as Z\n",
    "        \"\"\"\n",
    "        return np.ones_like(Z)\n",
    "\n",
    "print(\"\\n✓ Activation functions defined:\")\n",
    "print(\"  - ReLU for hidden layers: f(z) = max(0, z)\")\n",
    "print(\"  - Identity for output layer: f(z) = z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50062b6d-e0ef-4fae-abc9-241a494b83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DFNN CLASS IMPLEMENTATION\n",
      "================================================================================\n",
      "\n",
      "✓ DFNN class implemented successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: DEEP FEED-FORWARD NEURAL NETWORK CLASS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DFNN CLASS IMPLEMENTATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class DFNN:\n",
    "    \"\"\"\n",
    "    Deep Feed-Forward Neural Network for Regression\n",
    "    Implements mini-batch SGD with backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, architecture, learning_rate=0.001, batch_size=64, \n",
    "                 epochs=50, patience=10, verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize DFNN\n",
    "        \n",
    "        Args:\n",
    "            architecture: List of layer sizes [input_dim, hidden1, hidden2, ..., output_dim]\n",
    "            learning_rate: Learning rate η for SGD\n",
    "            batch_size: Mini-batch size B\n",
    "            epochs: Number of training epochs\n",
    "            patience: Early stopping patience\n",
    "            verbose: Print training progress\n",
    "        \"\"\"\n",
    "        self.architecture = architecture\n",
    "        self.num_layers = len(architecture) - 1  # Exclude input layer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self.parameters = {}\n",
    "        self.initialize_parameters()\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': []\n",
    "        }\n",
    "        \n",
    "        # Activation functions\n",
    "        self.activation = ActivationFunctions()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n✓ DFNN initialized with architecture: {architecture}\")\n",
    "            print(f\"  Learning rate: {learning_rate}\")\n",
    "            print(f\"  Batch size: {batch_size}\")\n",
    "            print(f\"  Epochs: {epochs}\")\n",
    "            print(f\"  Early stopping patience: {patience}\")\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize weights and biases using He initialization\n",
    "        \n",
    "        He initialization: W ~ N(0, sqrt(2/n_in))\n",
    "        Good for ReLU activations\n",
    "        \"\"\"\n",
    "        for l in range(1, self.num_layers + 1):\n",
    "            n_in = self.architecture[l - 1]\n",
    "            n_out = self.architecture[l]\n",
    "            \n",
    "            # He initialization for weights\n",
    "            self.parameters[f'W{l}'] = np.random.randn(n_in, n_out) * np.sqrt(2.0 / n_in)\n",
    "            \n",
    "            # Zero initialization for biases\n",
    "            self.parameters[f'b{l}'] = np.zeros((1, n_out))\n",
    "        \n",
    "        if self.verbose:\n",
    "            total_params = sum(W.size + self.parameters[f'b{l}'].size \n",
    "                             for l, W in enumerate([self.parameters[f'W{i}'] \n",
    "                             for i in range(1, self.num_layers + 1)], 1))\n",
    "            print(f\"\\n✓ Parameters initialized (He initialization)\")\n",
    "            print(f\"  Total parameters: {total_params:,}\")\n",
    "    \n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"\n",
    "        Forward propagation through the network\n",
    "        \n",
    "        For each layer l:\n",
    "            Z^(l) = H^(l-1) @ W^(l) + b^(l)\n",
    "            H^(l) = σ^(l)(Z^(l))\n",
    "        \n",
    "        Args:\n",
    "            X: Input data (batch_size, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            cache: Dictionary containing all Z and H values for backprop\n",
    "        \"\"\"\n",
    "        cache = {}\n",
    "        H = X\n",
    "        cache['H0'] = X\n",
    "        \n",
    "        # Forward through all layers\n",
    "        for l in range(1, self.num_layers + 1):\n",
    "            W = self.parameters[f'W{l}']\n",
    "            b = self.parameters[f'b{l}']\n",
    "            \n",
    "            # Linear transformation\n",
    "            Z = H @ W + b\n",
    "            cache[f'Z{l}'] = Z\n",
    "            \n",
    "            # Apply activation\n",
    "            if l < self.num_layers:\n",
    "                # Hidden layers: ReLU\n",
    "                H = self.activation.relu(Z)\n",
    "            else:\n",
    "                # Output layer: Identity (for regression)\n",
    "                H = self.activation.identity(Z)\n",
    "            \n",
    "            cache[f'H{l}'] = H\n",
    "        \n",
    "        return cache\n",
    "    \n",
    "    def compute_loss(self, Y_true, Y_pred):\n",
    "        \"\"\"\n",
    "        Compute Mean Squared Error loss\n",
    "        \n",
    "        J = (1/2N) * ||Y_pred - Y_true||²\n",
    "        \n",
    "        Args:\n",
    "            Y_true: True labels (batch_size, output_dim)\n",
    "            Y_pred: Predicted labels (batch_size, output_dim)\n",
    "        \n",
    "        Returns:\n",
    "            loss: Scalar loss value\n",
    "        \"\"\"\n",
    "        batch_size = Y_true.shape[0]\n",
    "        loss = (1.0 / (2.0 * batch_size)) * np.sum((Y_pred - Y_true) ** 2)\n",
    "        return loss\n",
    "    \n",
    "    def backward_propagation(self, cache, Y_true):\n",
    "        \"\"\"\n",
    "        Backward propagation (backpropagation) to compute gradients\n",
    "        \n",
    "        Output layer: δ^(L) = (1/B) * (Ŷ - Y)\n",
    "        Hidden layers: δ^(l) = (δ^(l+1) @ W^(l+1)ᵀ) ⊙ σ'(Z^(l))\n",
    "        \n",
    "        Gradients:\n",
    "            ∂J/∂W^(l) = (1/B) * H^(l-1)ᵀ @ δ^(l)\n",
    "            ∂J/∂b^(l) = (1/B) * sum(δ^(l), axis=0)\n",
    "        \n",
    "        Args:\n",
    "            cache: Forward propagation cache\n",
    "            Y_true: True labels (batch_size, output_dim)\n",
    "        \n",
    "        Returns:\n",
    "            gradients: Dictionary containing all gradients\n",
    "        \"\"\"\n",
    "        gradients = {}\n",
    "        batch_size = Y_true.shape[0]\n",
    "        L = self.num_layers\n",
    "        \n",
    "        # Output layer gradient (for MSE + Identity)\n",
    "        Y_pred = cache[f'H{L}']\n",
    "        delta = (1.0 / batch_size) * (Y_pred - Y_true)\n",
    "        \n",
    "        # Backpropagate through all layers\n",
    "        for l in range(L, 0, -1):\n",
    "            # Compute parameter gradients\n",
    "            H_prev = cache[f'H{l-1}']\n",
    "            gradients[f'dW{l}'] = H_prev.T @ delta\n",
    "            gradients[f'db{l}'] = np.sum(delta, axis=0, keepdims=True)\n",
    "            \n",
    "            # Propagate error to previous layer (if not input layer)\n",
    "            if l > 1:\n",
    "                W = self.parameters[f'W{l}']\n",
    "                Z_prev = cache[f'Z{l-1}']\n",
    "                \n",
    "                # δ^(l-1) = (δ^(l) @ W^(l)ᵀ) ⊙ σ'(Z^(l-1))\n",
    "                delta = (delta @ W.T) * self.activation.relu_derivative(Z_prev)\n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def update_parameters(self, gradients):\n",
    "        \"\"\"\n",
    "        Update parameters using SGD\n",
    "        \n",
    "        W^(l) ← W^(l) - η * ∂J/∂W^(l)\n",
    "        b^(l) ← b^(l) - η * ∂J/∂b^(l)\n",
    "        \n",
    "        Args:\n",
    "            gradients: Dictionary containing all gradients\n",
    "        \"\"\"\n",
    "        for l in range(1, self.num_layers + 1):\n",
    "            self.parameters[f'W{l}'] -= self.learning_rate * gradients[f'dW{l}']\n",
    "            self.parameters[f'b{l}'] -= self.learning_rate * gradients[f'db{l}']\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Train the network using mini-batch SGD\n",
    "        \n",
    "        Args:\n",
    "            X_train: Training features (N_train, input_dim)\n",
    "            y_train: Training labels (N_train, output_dim)\n",
    "            X_val: Validation features (N_val, input_dim)\n",
    "            y_val: Validation labels (N_val, output_dim)\n",
    "        \"\"\"\n",
    "        N_train = X_train.shape[0]\n",
    "        num_batches = int(np.ceil(N_train / self.batch_size))\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"TRAINING DFNN\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            # Shuffle training data\n",
    "            indices = np.random.permutation(N_train)\n",
    "            X_train_shuffled = X_train[indices]\n",
    "            y_train_shuffled = y_train[indices]\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            \n",
    "            # Mini-batch training\n",
    "            for batch_idx in range(num_batches):\n",
    "                # Get mini-batch\n",
    "                start_idx = batch_idx * self.batch_size\n",
    "                end_idx = min(start_idx + self.batch_size, N_train)\n",
    "                \n",
    "                X_batch = X_train_shuffled[start_idx:end_idx]\n",
    "                y_batch = y_train_shuffled[start_idx:end_idx]\n",
    "                \n",
    "                # Forward propagation\n",
    "                cache = self.forward_propagation(X_batch)\n",
    "                \n",
    "                # Compute loss\n",
    "                Y_pred = cache[f'H{self.num_layers}']\n",
    "                batch_loss = self.compute_loss(y_batch, Y_pred)\n",
    "                epoch_loss += batch_loss * (end_idx - start_idx)\n",
    "                \n",
    "                # Backward propagation\n",
    "                gradients = self.backward_propagation(cache, y_batch)\n",
    "                \n",
    "                # Update parameters\n",
    "                self.update_parameters(gradients)\n",
    "            \n",
    "            # Average epoch loss\n",
    "            epoch_loss /= N_train\n",
    "            \n",
    "            # Validation loss\n",
    "            cache_val = self.forward_propagation(X_val)\n",
    "            Y_val_pred = cache_val[f'H{self.num_layers}']\n",
    "            val_loss = self.compute_loss(y_val, Y_val_pred)\n",
    "            \n",
    "            # Save history\n",
    "            self.history['train_loss'].append(epoch_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            \n",
    "            # Print progress\n",
    "            if self.verbose and (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1:3d}/{self.epochs} | \"\n",
    "                      f\"Train Loss: {epoch_loss:.6f} | \"\n",
    "                      f\"Val Loss: {val_loss:.6f}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best parameters\n",
    "                self.best_parameters = {k: v.copy() for k, v in self.parameters.items()}\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= self.patience:\n",
    "                print(f\"\\n✓ Early stopping at epoch {epoch+1}\")\n",
    "                print(f\"  Best validation loss: {best_val_loss:.6f}\")\n",
    "                # Restore best parameters\n",
    "                self.parameters = self.best_parameters\n",
    "                break\n",
    "        \n",
    "        print(\"\\n✓ Training completed!\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on new data\n",
    "        \n",
    "        Args:\n",
    "            X: Input features (N, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            predictions: Predicted values (N, output_dim)\n",
    "        \"\"\"\n",
    "        cache = self.forward_propagation(X)\n",
    "        predictions = cache[f'H{self.num_layers}']\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, X, y, dataset_name=\"Test\"):\n",
    "        \"\"\"\n",
    "        Evaluate model performance\n",
    "        \n",
    "        Args:\n",
    "            X: Features\n",
    "            y: True labels\n",
    "            dataset_name: Name for printing\n",
    "        \n",
    "        Returns:\n",
    "            metrics: Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        \n",
    "        # MSE\n",
    "        mse = np.mean((predictions - y) ** 2)\n",
    "        \n",
    "        # RMSE\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # R² score\n",
    "        ss_res = np.sum((y - predictions) ** 2)\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        # MAE\n",
    "        mae = np.mean(np.abs(predictions - y))\n",
    "        \n",
    "        metrics = {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mae': mae\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{dataset_name} Set Performance:\")\n",
    "        print(f\"  MSE:  {mse:.4f}\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE:  {mae:.4f}\")\n",
    "        print(f\"  R²:   {r2:.4f}\")\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "print(\"\\n✓ DFNN class implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00e84482-5c78-4a85-9737-1025a745bc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525308"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4b34bb71-0b3c-40a1-bfb3-8b1900742f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "Network Architecture: [28, 64, 32, 16, 1]\n",
      "  Input layer: 28 features\n",
      "  Hidden layer 1: 64 neurons (ReLU)\n",
      "  Hidden layer 2: 32 neurons (ReLU)\n",
      "  Hidden layer 3: 16 neurons (ReLU)\n",
      "  Output layer: 1 neuron (Identity)\n",
      "\n",
      "✓ Parameters initialized (He initialization)\n",
      "  Total parameters: 4,481\n",
      "\n",
      "✓ DFNN initialized with architecture: [28, 64, 32, 16, 1]\n",
      "  Learning rate: 0.005\n",
      "  Batch size: 64\n",
      "  Epochs: 1000\n",
      "  Early stopping patience: 20\n",
      "\n",
      "================================================================================\n",
      "TRAINING DFNN\n",
      "================================================================================\n",
      "Epoch  10/1000 | Train Loss: 0.001332 | Val Loss: 0.000772\n",
      "Epoch  20/1000 | Train Loss: 0.001312 | Val Loss: 0.000773\n",
      "Epoch  30/1000 | Train Loss: 0.001297 | Val Loss: 0.000758\n",
      "Epoch  40/1000 | Train Loss: 0.001285 | Val Loss: 0.000753\n",
      "Epoch  50/1000 | Train Loss: 0.001275 | Val Loss: 0.000748\n",
      "Epoch  60/1000 | Train Loss: 0.001267 | Val Loss: 0.000751\n",
      "Epoch  70/1000 | Train Loss: 0.001260 | Val Loss: 0.000743\n",
      "Epoch  80/1000 | Train Loss: 0.001254 | Val Loss: 0.000748\n",
      "Epoch  90/1000 | Train Loss: 0.001249 | Val Loss: 0.000740\n",
      "Epoch 100/1000 | Train Loss: 0.001245 | Val Loss: 0.000741\n",
      "Epoch 110/1000 | Train Loss: 0.001241 | Val Loss: 0.000736\n",
      "Epoch 120/1000 | Train Loss: 0.001237 | Val Loss: 0.000735\n",
      "Epoch 130/1000 | Train Loss: 0.001234 | Val Loss: 0.000735\n",
      "Epoch 140/1000 | Train Loss: 0.001232 | Val Loss: 0.000734\n",
      "Epoch 150/1000 | Train Loss: 0.001229 | Val Loss: 0.000734\n",
      "Epoch 160/1000 | Train Loss: 0.001227 | Val Loss: 0.000733\n",
      "Epoch 170/1000 | Train Loss: 0.001225 | Val Loss: 0.000735\n",
      "Epoch 180/1000 | Train Loss: 0.001223 | Val Loss: 0.000731\n",
      "Epoch 190/1000 | Train Loss: 0.001221 | Val Loss: 0.000732\n",
      "Epoch 200/1000 | Train Loss: 0.001219 | Val Loss: 0.000731\n",
      "Epoch 210/1000 | Train Loss: 0.001217 | Val Loss: 0.000730\n",
      "Epoch 220/1000 | Train Loss: 0.001215 | Val Loss: 0.000729\n",
      "Epoch 230/1000 | Train Loss: 0.001214 | Val Loss: 0.000729\n",
      "\n",
      "✓ Early stopping at epoch 239\n",
      "  Best validation loss: 0.000727\n",
      "\n",
      "✓ Training completed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: TRAIN THE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define architecture\n",
    "input_dim = F_train.shape[1]\n",
    "architecture = [input_dim, 64, 32, 16, 1]\n",
    "\n",
    "print(f\"\\nNetwork Architecture: {architecture}\")\n",
    "print(f\"  Input layer: {architecture[0]} features\")\n",
    "print(f\"  Hidden layer 1: {architecture[1]} neurons (ReLU)\")\n",
    "print(f\"  Hidden layer 2: {architecture[2]} neurons (ReLU)\")\n",
    "print(f\"  Hidden layer 3: {architecture[3]} neurons (ReLU)\")\n",
    "print(f\"  Output layer: {architecture[4]} neuron (Identity)\")\n",
    "\n",
    "# Initialize model\n",
    "model = DFNN(\n",
    "    architecture=architecture,\n",
    "    learning_rate=0.005,\n",
    "    batch_size=64,\n",
    "    epochs=1000,\n",
    "    patience=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.train(F_train, y_tr, F_valid, y_vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35687a-1782-4c81-9587-3b406217138b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "daf4540d-5ae8-413c-93c3-0aab78535f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "--- Performance on Scaled Targets ---\n",
      "\n",
      "Training Set Performance:\n",
      "  MSE:  0.0026\n",
      "  RMSE: 0.0513\n",
      "  MAE:  0.0362\n",
      "  R²:   0.3358\n",
      "\n",
      "Validation Set Performance:\n",
      "  MSE:  0.0015\n",
      "  RMSE: 0.0392\n",
      "  MAE:  0.0273\n",
      "  R²:   0.3269\n",
      "\n",
      "--- Performance on Original Scale ---\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.4 TiB for an array with shape (1906350, 1906350) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  R²:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m: mse, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m: rmse, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m: mae, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m: r2}\n\u001b[1;32m---> 40\u001b[0m train_metrics_orig \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_original_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m val_metrics_orig \u001b[38;5;241m=\u001b[39m evaluate_original_scale(y_valid, y_val_pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#test_metrics_orig = evaluate_original_scale(y_test, y_test_pred, \"Test\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[57], line 25\u001b[0m, in \u001b[0;36mevaluate_original_scale\u001b[1;34m(y_true, y_pred, dataset_name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_original_scale\u001b[39m(y_true, y_pred, dataset_name):\n\u001b[1;32m---> 25\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     26\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n\u001b[0;32m     27\u001b[0m     mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true))\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.4 TiB for an array with shape (1906350, 1906350) and data type float64"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on all datasets (on scaled targets)\n",
    "print(\"\\n--- Performance on Scaled Targets ---\")\n",
    "train_metrics = model.evaluate(F_train, y_tr, \"Training\")\n",
    "val_metrics = model.evaluate(F_valid, y_vl, \"Validation\")\n",
    "#test_metrics = model.evaluate(F_test, y_test_scaled, \"Test\")\n",
    "\n",
    "# Make predictions and inverse transform for actual scale\n",
    "print(\"\\n--- Performance on Original Scale ---\")\n",
    "y_train_pred_scaled = model.predict(F_train)\n",
    "y_val_pred_scaled = model.predict(F_valid)\n",
    "#y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "#y_train_pred = scaler.inverse_transform(y_train_pred_scaled)\n",
    "#y_val_pred = scaler.inverse_transform(y_val_pred_scaled)\n",
    "#y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
    "y_train_pred = y_train_pred_scaled\n",
    "y_val_pred = y_val_pred_scaled\n",
    "# Evaluate on original scale\n",
    "def evaluate_original_scale(y_true, y_pred, dataset_name):\n",
    "    mse = np.mean((y_pred - y_true) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_pred - y_true))\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Set (Original Scale):\")\n",
    "    print(f\"  MSE:  {mse:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f} bikes/hour\")\n",
    "    print(f\"  MAE:  {mae:.2f} bikes/hour\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "train_metrics_orig = evaluate_original_scale(y_train, y_train_pred, \"Training\")\n",
    "val_metrics_orig = evaluate_original_scale(y_valid, y_val_pred, \"Validation\")\n",
    "#test_metrics_orig = evaluate_original_scale(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a9cdc-6e35-4e84-b280-3a7e05dfcff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "211ef227-182a-4397-adc6-b2bb74233ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "--- Performance on Scaled Targets ---\n",
      "\n",
      "Training Set Performance:\n",
      "  MSE:  0.0026\n",
      "  RMSE: 0.0506\n",
      "  MAE:  0.0358\n",
      "  R²:   0.3524\n",
      "\n",
      "Validation Set Performance:\n",
      "  MSE:  0.0015\n",
      "  RMSE: 0.0389\n",
      "  MAE:  0.0270\n",
      "  R²:   0.3381\n",
      "\n",
      "--- Performance on Original Scale ---\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 26.4 TiB for an array with shape (1906350, 1906350) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  R²:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m: mse, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m: rmse, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m: mae, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m: r2}\n\u001b[1;32m---> 40\u001b[0m train_metrics_orig \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_original_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m val_metrics_orig \u001b[38;5;241m=\u001b[39m evaluate_original_scale(y_valid, y_val_pred, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#test_metrics_orig = evaluate_original_scale(y_test, y_test_pred, \"Test\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[94], line 25\u001b[0m, in \u001b[0;36mevaluate_original_scale\u001b[1;34m(y_true, y_pred, dataset_name)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_original_scale\u001b[39m(y_true, y_pred, dataset_name):\n\u001b[1;32m---> 25\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     26\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mse)\n\u001b[0;32m     27\u001b[0m     mae \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true))\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 26.4 TiB for an array with shape (1906350, 1906350) and data type float64"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Evaluate on all datasets (on scaled targets)\n",
    "print(\"\\n--- Performance on Scaled Targets ---\")\n",
    "train_metrics = model.evaluate(F_train, y_tr, \"Training\")\n",
    "val_metrics = model.evaluate(F_valid, y_vl, \"Validation\")\n",
    "#test_metrics = model.evaluate(F_test, y_test_scaled, \"Test\")\n",
    "\n",
    "# Make predictions and inverse transform for actual scale\n",
    "print(\"\\n--- Performance on Original Scale ---\")\n",
    "y_train_pred_scaled = model.predict(F_train)\n",
    "y_val_pred_scaled = model.predict(F_valid)\n",
    "#y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "#y_train_pred = scaler.inverse_transform(y_train_pred_scaled)\n",
    "#y_val_pred = scaler.inverse_transform(y_val_pred_scaled)\n",
    "#y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
    "y_train_pred = y_train_pred_scaled\n",
    "y_val_pred = y_val_pred_scaled\n",
    "# Evaluate on original scale\n",
    "def evaluate_original_scale(y_true, y_pred, dataset_name):\n",
    "    mse = np.mean((y_pred - y_true) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_pred - y_true))\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Set (Original Scale):\")\n",
    "    print(f\"  MSE:  {mse:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f} bikes/hour\")\n",
    "    print(f\"  MAE:  {mae:.2f} bikes/hour\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "train_metrics_orig = evaluate_original_scale(y_train, y_train_pred, \"Training\")\n",
    "val_metrics_orig = evaluate_original_scale(y_valid, y_val_pred, \"Validation\")\n",
    "#test_metrics_orig = evaluate_original_scale(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc72590-9908-43e9-9a1e-ef41f23e94cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "637899c0-596e-46db-9ec9-cfa77df995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(F_test)\n",
    "#test_metrics = evaluate_original_scale(y_test, y_test_pred, \"Testing Metrics\")\n",
    "\n",
    "#y_train_pred = y_train_pred_scaled\n",
    "#y_val_pred = y_val_pred_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "47dcc8fd-f208-4e36-908d-cd4a6d68c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016068799194225297\n"
     ]
    }
   ],
   "source": [
    "#test_metrics = evaluate_original_scale(y_test, y_test_pred, \"Testing Metrics\")\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bc1f6d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00273964]\n",
      " [ 0.00811288]\n",
      " [ 0.01705129]\n",
      " ...\n",
      " [ 0.00526618]\n",
      " [ 0.00444512]\n",
      " [ 0.00639858]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2691281f-711f-47cf-b1ad-85461bcfd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['y_pred'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d448637b-100b-47e6-b3aa-666853337c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(869269, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feba3db5-0efb-41c3-aad2-9f9317a16de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_pred = scaler.inverse_transform(y_test_pred_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "40e12098-6291-475c-a6fe-ed08a092aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pickle.load(open(r'C:\\CB\\q3\\train.pkl', 'rb')).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "113258fa-363b-4e0e-80a2-aeb4484518d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date'] = pd.to_datetime(df1['date'], unit='D', origin='2024-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b3b49587-f6aa-4714-a589-785a913fc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = df1['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "69e38c71-fd82-4855-a6cb-c4907401394a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-01-01 00:00:00')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "93e21def-a5c9-4c9f-b473-31448a84395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_d = df_test1['date'] - min_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c966b9f7-8fe6-4d29-9f6b-52dde646bcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        550 days\n",
       "1        551 days\n",
       "2        552 days\n",
       "3        553 days\n",
       "4        554 days\n",
       "           ...   \n",
       "869264   722 days\n",
       "869265   723 days\n",
       "869266   724 days\n",
       "869267   725 days\n",
       "869268   726 days\n",
       "Name: date, Length: 869269, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6672cba4-c5e8-4e82-a883-38280fee55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e801680c-aa98-42aa-9aab-68b2c7a87c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_numeric = time_d / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5c92dd07-342f-460b-84ef-263b5b59b482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         550.0\n",
       "1         551.0\n",
       "2         552.0\n",
       "3         553.0\n",
       "4         554.0\n",
       "          ...  \n",
       "869264    722.0\n",
       "869265    723.0\n",
       "869266    724.0\n",
       "869267    725.0\n",
       "869268    726.0\n",
       "Name: date, Length: 869269, dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a168e130-3de7-4a42-b5f3-feda0e2d4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1['date'] = pd.to_numeric(days_numeric, downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fed5d-67b0-47d7-9a03-4cb7e0494266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c1584-b3cd-413d-a560-3f012c8876a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d3376089-4b04-4a6f-8043-707c39236cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>y</th>\n",
       "      <th>code_id</th>\n",
       "      <th>t_idx</th>\n",
       "      <th>y_lag_1</th>\n",
       "      <th>y_lag_2</th>\n",
       "      <th>y_lag_3</th>\n",
       "      <th>y_lag_7</th>\n",
       "      <th>y_roll_mean_3</th>\n",
       "      <th>y_roll_std_3</th>\n",
       "      <th>y_roll_mean_7</th>\n",
       "      <th>y_roll_std_7</th>\n",
       "      <th>sin_7</th>\n",
       "      <th>cos_7</th>\n",
       "      <th>sin_30</th>\n",
       "      <th>cos_30</th>\n",
       "      <th>sin_90</th>\n",
       "      <th>cos_90</th>\n",
       "      <th>sin_365</th>\n",
       "      <th>cos_365</th>\n",
       "      <th>dow</th>\n",
       "      <th>dom</th>\n",
       "      <th>month</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>year</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>date1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_0</td>\n",
       "      <td>550</td>\n",
       "      <td>-1.369722</td>\n",
       "      <td>0.039572</td>\n",
       "      <td>1.779249</td>\n",
       "      <td>0.614737</td>\n",
       "      <td>-0.156733</td>\n",
       "      <td>0.283154</td>\n",
       "      <td>0.028497</td>\n",
       "      <td>0.578046</td>\n",
       "      <td>3.074321</td>\n",
       "      <td>0.980909</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.993053</td>\n",
       "      <td>0.722489</td>\n",
       "      <td>-0.183440</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>-0.034966</td>\n",
       "      <td>-0.014534</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.059350</td>\n",
       "      <td>-0.003217</td>\n",
       "      <td>0.090807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2025</td>\n",
       "      <td>-0.002740</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_0</td>\n",
       "      <td>551</td>\n",
       "      <td>-1.382292</td>\n",
       "      <td>0.046213</td>\n",
       "      <td>1.788899</td>\n",
       "      <td>0.588849</td>\n",
       "      <td>-0.113548</td>\n",
       "      <td>0.281461</td>\n",
       "      <td>0.028017</td>\n",
       "      <td>0.556442</td>\n",
       "      <td>3.054377</td>\n",
       "      <td>0.980679</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>1.012733</td>\n",
       "      <td>0.697357</td>\n",
       "      <td>-0.177849</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>-0.046088</td>\n",
       "      <td>-0.013790</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.035671</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.075164</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.781832</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.069756</td>\n",
       "      <td>0.997564</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_0</td>\n",
       "      <td>552</td>\n",
       "      <td>-1.400969</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>1.945576</td>\n",
       "      <td>0.591494</td>\n",
       "      <td>-0.072045</td>\n",
       "      <td>0.283010</td>\n",
       "      <td>0.038164</td>\n",
       "      <td>0.582346</td>\n",
       "      <td>3.121780</td>\n",
       "      <td>0.979803</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>1.194460</td>\n",
       "      <td>0.721132</td>\n",
       "      <td>-0.178476</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>-0.038439</td>\n",
       "      <td>-0.011187</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.029482</td>\n",
       "      <td>-0.010477</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.075164</td>\n",
       "      <td>0.090807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>0.406737</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.139173</td>\n",
       "      <td>0.990268</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_0</td>\n",
       "      <td>553</td>\n",
       "      <td>-1.374383</td>\n",
       "      <td>0.045059</td>\n",
       "      <td>1.815760</td>\n",
       "      <td>0.600794</td>\n",
       "      <td>-0.066371</td>\n",
       "      <td>0.306641</td>\n",
       "      <td>0.038751</td>\n",
       "      <td>0.678451</td>\n",
       "      <td>3.087187</td>\n",
       "      <td>0.972990</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>1.206392</td>\n",
       "      <td>0.775389</td>\n",
       "      <td>-0.177323</td>\n",
       "      <td>0.006861</td>\n",
       "      <td>-0.058894</td>\n",
       "      <td>-0.011347</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>-0.011462</td>\n",
       "      <td>0.020968</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>0.075164</td>\n",
       "      <td>0.090807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066523</td>\n",
       "      <td>0.029567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.587785</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_0</td>\n",
       "      <td>554</td>\n",
       "      <td>-1.382681</td>\n",
       "      <td>0.038729</td>\n",
       "      <td>1.834345</td>\n",
       "      <td>0.601960</td>\n",
       "      <td>-0.119939</td>\n",
       "      <td>0.273871</td>\n",
       "      <td>0.026979</td>\n",
       "      <td>0.726376</td>\n",
       "      <td>3.081610</td>\n",
       "      <td>0.971104</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>1.209588</td>\n",
       "      <td>0.803587</td>\n",
       "      <td>-0.183263</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>-0.045593</td>\n",
       "      <td>-0.006697</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.029528</td>\n",
       "      <td>-0.012795</td>\n",
       "      <td>-0.006153</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.020968</td>\n",
       "      <td>0.033599</td>\n",
       "      <td>0.075164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043244</td>\n",
       "      <td>0.028356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>0.743145</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>0.275637</td>\n",
       "      <td>0.961262</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>2025</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code  date       f_0       f_1       f_2       f_3       f_4       f_5  \\\n",
       "0  s_0   550 -1.369722  0.039572  1.779249  0.614737 -0.156733  0.283154   \n",
       "1  s_0   551 -1.382292  0.046213  1.788899  0.588849 -0.113548  0.281461   \n",
       "2  s_0   552 -1.400969  0.040787  1.945576  0.591494 -0.072045  0.283010   \n",
       "3  s_0   553 -1.374383  0.045059  1.815760  0.600794 -0.066371  0.306641   \n",
       "4  s_0   554 -1.382681  0.038729  1.834345  0.601960 -0.119939  0.273871   \n",
       "\n",
       "        f_6       f_7       f_8       f_9      f_10      f_11      f_12  \\\n",
       "0  0.028497  0.578046  3.074321  0.980909  0.017531  0.993053  0.722489   \n",
       "1  0.028017  0.556442  3.054377  0.980679  0.006043  1.012733  0.697357   \n",
       "2  0.038164  0.582346  3.121780  0.979803  0.003479  1.194460  0.721132   \n",
       "3  0.038751  0.678451  3.087187  0.972990  0.005802  1.206392  0.775389   \n",
       "4  0.026979  0.726376  3.081610  0.971104  0.001889  1.209588  0.803587   \n",
       "\n",
       "       f_13      f_14      f_15      f_16      f_17      f_18      f_19  \\\n",
       "0 -0.183440  0.003627 -0.034966 -0.014534 -0.000058  0.059350 -0.003217   \n",
       "1 -0.177849  0.007046 -0.046088 -0.013790 -0.000067  0.035671  0.004659   \n",
       "2 -0.178476  0.009262 -0.038439 -0.011187 -0.000064  0.029482 -0.010477   \n",
       "3 -0.177323  0.006861 -0.058894 -0.011347 -0.000055  0.027638 -0.011462   \n",
       "4 -0.183263  0.003685 -0.045593 -0.006697 -0.000054  0.029528 -0.012795   \n",
       "\n",
       "          y  code_id  t_idx   y_lag_1   y_lag_2   y_lag_3  y_lag_7  \\\n",
       "0  0.090807        0      0       NaN       NaN       NaN      NaN   \n",
       "1  0.075164        0      1  0.090807       NaN       NaN      NaN   \n",
       "2  0.033599        0      2  0.075164  0.090807       NaN      NaN   \n",
       "3  0.020968        0      3  0.033599  0.075164  0.090807      NaN   \n",
       "4 -0.006153        0      4  0.020968  0.033599  0.075164      NaN   \n",
       "\n",
       "   y_roll_mean_3  y_roll_std_3  y_roll_mean_7  y_roll_std_7     sin_7  \\\n",
       "0            NaN           NaN            NaN           NaN  0.000000   \n",
       "1            NaN           NaN            NaN           NaN  0.781832   \n",
       "2            NaN           NaN            NaN           NaN  0.974928   \n",
       "3       0.066523      0.029567            NaN           NaN  0.433884   \n",
       "4       0.043244      0.028356            NaN           NaN -0.433884   \n",
       "\n",
       "      cos_7    sin_30    cos_30    sin_90    cos_90   sin_365   cos_365  dow  \\\n",
       "0  1.000000  0.000000  1.000000  0.000000  1.000000  0.000000  1.000000    4   \n",
       "1  0.623490  0.207912  0.978148  0.069756  0.997564  0.017213  0.999852    5   \n",
       "2 -0.222521  0.406737  0.913545  0.139173  0.990268  0.034422  0.999407    6   \n",
       "3 -0.900969  0.587785  0.809017  0.207912  0.978148  0.051620  0.998667    0   \n",
       "4 -0.900969  0.743145  0.669131  0.275637  0.961262  0.068802  0.997630    1   \n",
       "\n",
       "   dom  month  weekofyear  year    y_pred  date1  \n",
       "0    4      7          27  2025 -0.002740    550  \n",
       "1    5      7          27  2025  0.008113    551  \n",
       "2    6      7          27  2025  0.017051    552  \n",
       "3    7      7          28  2025  0.032811    553  \n",
       "4    8      7          28  2025  0.020006    554  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6a78d0d3-c815-4dd1-9c2b-e30afdb7c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_test1[['code','date','y_pred']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "08aa3585-8006-45e1-8401-047504bbf10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_0</td>\n",
       "      <td>550</td>\n",
       "      <td>-0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_0</td>\n",
       "      <td>551</td>\n",
       "      <td>0.008113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_0</td>\n",
       "      <td>552</td>\n",
       "      <td>0.017051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_0</td>\n",
       "      <td>553</td>\n",
       "      <td>0.032811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_0</td>\n",
       "      <td>554</td>\n",
       "      <td>0.020006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code  date    y_pred\n",
       "0  s_0   550 -0.002740\n",
       "1  s_0   551  0.008113\n",
       "2  s_0   552  0.017051\n",
       "3  s_0   553  0.032811\n",
       "4  s_0   554  0.020006"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f075de29-8846-4d8a-981e-085d03d80351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\CB\\q3\\DFNN_model_out.csv\n"
     ]
    }
   ],
   "source": [
    "out1 = out1.sort_values([\"code\", \"date\"]).reset_index(drop=True)\n",
    "#out[\"date\"] = pd.to_datetime(out[\"date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "out_path = 'C:\\CB\\q3\\DFNN_model_out.csv'\n",
    "out.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "efc935bd-1f7c-4ed7-8c9f-d8b710bd4c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09080688, 0.07516383, 0.03359878, ..., 0.00580495, 0.01965836,\n",
       "       0.00575009], shape=(869269,), dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PF_test=pd.todataframe(F_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "921b6267-0e6e-4c3b-a1c9-bd709d00e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize=(20,16))\n",
    "#plt.plot(out['y'], out['y_pred'])\n",
    "#plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
